package net.mguenther.idem.flake;

import net.mguenther.idem.Wait;
import net.mguenther.idem.encoder.LongEncoder;
import net.mguenther.idem.provider.LinearTimeProvider;
import net.mguenther.idem.provider.StaticWorkerIdProvider;
import net.mguenther.idem.provider.TimeProvider;
import org.junit.Before;
import org.junit.Test;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.concurrent.TimeUnit;

import static net.mguenther.idem.TestUtil.assertThatListIsStrictlyOrdered;
import static org.hamcrest.core.Is.is;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;

public class Flake64LTest {

    private final TimeProvider timeProvider = new LinearTimeProvider();

    private Flake64L flake;

    @Before
    public void prepareTest() {
        flake = new Flake64L(
                timeProvider,
                new StaticWorkerIdProvider("ASvmcvljs=!"), // this worker ID has its LSB set to 1
                new LongEncoder());
    }

    @Test
    public void generatedIdsShouldBeLinearlyIncreasingAcrossTimeSlots() {
        List<Long> generatedIds = new ArrayList<>();
        long started = System.nanoTime();
        while (System.nanoTime() - started < 200_000_000L) {
            generatedIds.add(flake.nextId());
        }
        assertFalse(generatedIds.isEmpty());
        assertThatListIsStrictlyOrdered(generatedIds);
    }

    @Test
    public void shouldIsolateProcessesProperlyByWorkerIds() throws InterruptedException {

        IdGeneratorWorker<Long> worker1 = new IdGeneratorWorker<>(new Flake64L(timeProvider, new StaticWorkerIdProvider("A"), new LongEncoder()));
        IdGeneratorWorker<Long> worker2 = new IdGeneratorWorker<>(new Flake64L(timeProvider, new StaticWorkerIdProvider("B"), new LongEncoder()));

        Thread workerThread1 = new Thread(worker1);
        Thread workerThread2 = new Thread(worker2);

        workerThread1.start();
        workerThread2.start();

        Wait.delay(1, TimeUnit.SECONDS);

        worker1.stop();
        worker2.stop();

        workerThread1.join(1_000);
        workerThread2.join(1_000);

        List<Long> generatedIdsByWorker1 = worker1.getGeneratedIds();
        List<Long> generatedIdsByWorker2 = worker2.getGeneratedIds();

        assertFalse(generatedIdsByWorker1.isEmpty());
        assertFalse(generatedIdsByWorker2.isEmpty());

        Set<Long> combinedGeneratedIds = new HashSet<>();
        combinedGeneratedIds.addAll(generatedIdsByWorker1);
        combinedGeneratedIds.addAll(generatedIdsByWorker2);

        // the combined set of IDs would be smaller in size than the sum of the individual lists of
        // generated IDs, if we'd experience any duplicates between the IDs generated by worker 1
        // and those generated by worker 2
        assertThat(combinedGeneratedIds.size(), is(generatedIdsByWorker1.size() + generatedIdsByWorker2.size()));
    }

    @Test
    public void idsThatHaveBeenGeneratedASecondApartAlsoAreASecondApartInIdSpace() throws InterruptedException {

        Long id1 = flake.nextId();

        Wait.delay(1, TimeUnit.SECONDS);

        Long id2 = flake.nextId();

        long timestampFromId1 = id1 >> 22;
        long timestampFromId2 = id2 >> 22;
        long timeBetween = timestampFromId2 - timestampFromId1;

        assertTrue(timeBetween > 1_000L && timeBetween < 2_000L);
    }
}

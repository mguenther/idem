package net.mguenther.idem.flake;

import net.mguenther.idem.Wait;
import net.mguenther.idem.encoder.LongEncoder;
import net.mguenther.idem.provider.LinearTimeProvider;
import net.mguenther.idem.provider.StaticWorkerIdProvider;
import net.mguenther.idem.provider.TimeProvider;
import org.junit.Before;
import org.junit.Test;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.concurrent.TimeUnit;

import static net.mguenther.idem.TestUtil.assertThatListIsStrictlyOrdered;
import static org.hamcrest.core.Is.is;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertThat;

public class Flake64LTest {

    private final TimeProvider timeProvider = new LinearTimeProvider();

    private Flake64L flake;

    @Before
    public void prepareTest() {
        flake = new Flake64L(
                timeProvider,
                new StaticWorkerIdProvider("ASvmcvljs=!"), // this worker ID has its LSB set to 1
                new LongEncoder());
    }

    @Test
    public void generatedIdsShouldBeLinearlyIncreasingAcrossTimeSlots() {
        List<Long> generatedIds = new ArrayList<>();
        long started = System.nanoTime();
        while (System.nanoTime() - started < 200_000_000L) {
            generatedIds.add(flake.nextId());
        }
        assertFalse(generatedIds.isEmpty());
        assertThatListIsStrictlyOrdered(generatedIds);
    }

    @Test
    public void shouldIsolateProcessesProperlyByWorkerIds() throws InterruptedException {

        Flake64Worker worker1 = new Flake64Worker(new Flake64L(timeProvider, new StaticWorkerIdProvider("A"), new LongEncoder()));
        Flake64Worker worker2 = new Flake64Worker(new Flake64L(timeProvider, new StaticWorkerIdProvider("B"), new LongEncoder()));

        Thread workerThread1 = new Thread(worker1);
        Thread workerThread2 = new Thread(worker2);

        workerThread1.start();
        workerThread2.start();

        Wait.delay(1, TimeUnit.SECONDS);

        worker1.stop();
        worker2.stop();

        workerThread1.join(1_000);
        workerThread2.join(1_000);

        List<Long> generatedIdsByWorker1 = worker1.getGeneratedIds();
        List<Long> generatedIdsByWorker2 = worker2.getGeneratedIds();

        Set<Long> combinedGeneratedIds = new HashSet<>();
        combinedGeneratedIds.addAll(generatedIdsByWorker1);
        combinedGeneratedIds.addAll(generatedIdsByWorker2);

        // the combined set of IDs would be smaller in size than the sum of the individual lists of
        // generated IDs, if we'd experience any duplicates between the IDs generated by worker 1
        // and those generated by worker 2
        assertThat(combinedGeneratedIds.size(), is(generatedIdsByWorker1.size() + generatedIdsByWorker2.size()));
    }

    private class Flake64Worker implements Runnable {

        private final Flake64<Long> flake;

        private final List<Long> generatedIds;

        private volatile boolean running = true;

        public Flake64Worker(final Flake64<Long> flake) {
            this.flake = flake;
            this.generatedIds = new ArrayList<>();
        }

        @Override
        public void run() {
            while (running) {
                generatedIds.add(flake.nextId());
            }
        }

        public void stop() {
            running = false;
        }

        public List<Long> getGeneratedIds() {
            return generatedIds;
        }
    }
}
